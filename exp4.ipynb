{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([1]), name=\"weight1\")\n",
    "w2 = tf.Variable(tf.random.normal([1]), name=\"weight2\")\n",
    "w3 = tf.Variable(tf.random.normal([1]), name=\"weight3\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "def compute_cost(x1, x2, x3, y):\n",
    "    hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "    return hypothesis, cost\n",
    "\n",
    "def train_step(x1, x2, x3, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis, cost = compute_cost(x1, x2, x3, y)\n",
    "    gradients = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [w1, w2, w3, b]))\n",
    "    return hypothesis, cost\n",
    "\n",
    "for step in range(2001):\n",
    "    hy_val, cost_val = train_step(x1_data, x2_data, x3_data, y_data)\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val.numpy(), \"\\nPrediction:\\n\", hy_val.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.], [93., 88., 93.], [89., 91., 90.],\n",
    "          [96., 98., 100.], [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3, 1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "def compute_cost(X, Y):\n",
    "    hypothesis = tf.matmul(X, W) + b\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    return hypothesis, cost\n",
    "\n",
    "def train_step(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis, cost = compute_cost(X, Y)\n",
    "    gradients = tape.gradient(cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    return hypothesis, cost\n",
    "\n",
    "for step in range(2001):\n",
    "    hy_val, cost_val = train_step(x_data, y_data)\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val.numpy(), \"\\nPrediction:\\n\", hy_val.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
